{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "secret-issue",
   "metadata": {},
   "source": [
    "## Training eines neuronalen Netzes zur Erkennung von Ziffern\n",
    "\n",
    "Bei Training der Snake-KI und beim Training des Chat-Bots haben wir neuronale Netze als \"Black Box\" verwendet. Heute wollen wir uns etwas genauer anschauen, wie das Training eines neuronalen Netzes funktioniert.\n",
    "\n",
    "Wenn man eine neue Programmiersprache lernt, beginnt man meistens mit einem *Hello World* – einem kleinen Programm, das die Meldung `Hello World!` ausgibt.\n",
    "Im Bereich der KI bzw. des maschinellen Lernens verwendet man gerne den *[MNIST Datensatz](https://de.wikipedia.org/wiki/MNIST-Datenbank)* als Beispiel verwendet.\n",
    "\n",
    "In diesem Praktikum geht es um folgende Punkte:\n",
    "\n",
    "**1. Wie trainiert man ein neuronales Netz?**<br>\n",
    "   Wir lernen, wie man\n",
    "   - Trainingsdaten lädt,\n",
    "   - ein neuronales Netz aufbaut,\n",
    "   - das neuronale Netz trainiert und\n",
    "   - die Qualität des Netzes misst.\n",
    "\n",
    "\n",
    "**2. Wovon hängt die Qualität der Erkennung ab?**<br>\n",
    "   Jenachdem, \n",
    "   - wie wir unser Netz bauen, \n",
    "   - wie viele Trainingsdaten wir verwenden und \n",
    "   - wie lange wir das Netz trainieren\n",
    "   sind die Ergebnisse besser oder schlechter. Dabei gibt es typische Probleme, die beim Training von KI-Modellen immer wieder auftauchen. Wie beim Fußball ist es \n",
    "   wichtig, als \"Trainer\" diese Probleme zu erkennen und zu wissen, was man dagegen tun kann.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-membrane",
   "metadata": {},
   "source": [
    "In diesem Praktikum verwenden wir ein *Jupyter Notebook*. Darin kann man Erklärungen direkt in das Programm einbauen. Die folgende *Code-Zelle* gibt `Hello World!` aus, wenn Du sie ausführst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-rough",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-elder",
   "metadata": {},
   "source": [
    "Hier geht es mit dem Trainingsprogramm los. Die folgende Code-Zelle importiert die notwendigen Bibliotheken, die wir im folgenden benötigen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-cleaner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-bahamas",
   "metadata": {},
   "source": [
    "### Trainingsdaten laden\n",
    "\n",
    "Jetzt laden wir die Trainingsdaten aus dem Internet und schauen uns ein paar Beispiele an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets.MNIST(root=\"\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_set = datasets.MNIST(root=\"\", train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ea297c-a3d9-487f-a9fc-ed21b9075f39",
   "metadata": {},
   "source": [
    "Am Anfang sollen nur die ersten 500 Datensätze der Trainingsdaten ausgewählt werden. Damit geht das Training deutlich schneller, aber dieses Vorgehen hat auch Nachteile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91b8f72-2780-406b-96c5-316c3f290d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500\n",
    "train_set.data = train_set.data[0:500] # Hier die ersten 500 Datensätze der Traningsdaten auswählen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-japanese",
   "metadata": {},
   "source": [
    "#### \"Form\" der Trainingsdaten\n",
    "\n",
    "Wir schauen uns nun an, welche \"Form\" (*shape*) die Trainings- und Testdaten haben. Verstehst Du, was die drei Zahlen bedeuten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-audience",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train_set shape: \", train_set.data.shape)\n",
    "print(\"test_set shape: \", test_set.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-ceremony",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=64, pin_memory=True, num_workers=10, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=64, pin_memory=True, num_workers=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-enterprise",
   "metadata": {},
   "source": [
    "#### Trainingsbeispiele ansehen\n",
    "\n",
    "Die folgende Zelle lädt die ersten Trainingsdaten und zeigt ein paar Beispiele an. Damit können wir kontrollieren, dass alles geklappt hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-coalition",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_loader:\n",
    "    # Wir laden die erste Portion Daten\n",
    "    break;\n",
    "    \n",
    "figure = plt.figure()\n",
    "num_images = 18\n",
    "for i in range(num_images):\n",
    "    plt.subplot(3, 6, i+1, title=f\"{labels[i]}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(images[i].cpu().numpy().squeeze(), cmap=\"gray_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-version",
   "metadata": {},
   "source": [
    "### Aufbau des neuronalen Netzes\n",
    "\n",
    "Hier bauen wir nun das neuronale Netz. Wir versuchen es zunächst mit einem ganz einfachen Netz:\n",
    "\n",
    "- Eine Eigabeschicht, die die $28 \\cdot 28$ Pixel auf eine **versteckte Schicht** abbildet.\n",
    "  Diese versteckte Schicht hat `hidden_size` Neuronen. Wir beginnen mit zwei Neuronen \n",
    "  (`hidden_size = 2`). \n",
    "- Die Eingabeschicht verwendet als **Aktivierungsfunktion** die \n",
    "  *[Rectified Linear Unit (ReLU)](https://de.wikipedia.org/wiki/Rectifier_(neuronale_Netzwerke))*\n",
    "- Eine **Ausgabeschicht**, die für jede mögliche Ziffer ein Neuron enthält.\n",
    "  Hier benötigen wir keine Aktivierungsfunktion – das am \"stärksten feuernde\" Neuron gewinnt am Ende\n",
    "  bzw. die Werte werden automatisch so normiert, dass sie zwischen $0$ und $1$ liegen und in der Summe \n",
    "  $1$ ergeben ([Softmax](https://de.wikipedia.org/wiki/Softmax-Funktion)).\n",
    "  \n",
    "Zur Definition des Netzes benötigen wir eine Funktion `__init__()` um die Daten zu definieren, und eine \n",
    "Funktion `forward()` die Rechenschritte des Netzes ausführt.\n",
    "Den ganzen mathematischen Rest erledigt die Bibliothek *PyTorch*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 2\n",
    "\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ANN, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(28*28, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 10)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = x.view(-1, 28*28)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-blond",
   "metadata": {},
   "source": [
    "### Neuronales Netz, Verlustfunktion und Optimierer anlegen\n",
    "\n",
    "Neben dem neuronalen Netz erzeugen wir jetzt \n",
    "- Die Verlustfunktion, die wir optimieren. Sie misst, ob unser Netz die richtige Ziffer \"vorschlägt\" \n",
    "  und sich dabei möglichst sicher ist. Das heißt\n",
    "  - die Ausgabe des Neurons der \"richtigen\" Ziffer soll möglichst hoch,\n",
    "  - die Ausgabe der anderen Neuronen möglichst klein sein.\n",
    "  Dafür verwendet man die sogenannte *[Kreuzentropie](https://de.wikipedia.org/wiki/Kreuzentropie)* \n",
    "  (engl. *Cross Entropy*).\n",
    "- Den Optimierer, der beim Training die Verlustfunktion optimiert. Wir verwenden `optim.SGD`, wobei   \n",
    "  *SGD* für *Stochastic Gradient Descent* steht. Anschaulich gesprochen verhält sich dieser Optimierer\n",
    "  wie ein Skifahrer im Nebel – er fährt einfach dalang, wo es bergab geht, und hofft, dass er heil \n",
    "  im Tal ankommt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-logistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ANN()\n",
    "model = model.cuda()\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "training_loss = []\n",
    "testing_loss = []\n",
    "training_acc = []\n",
    "testing_acc = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-election",
   "metadata": {},
   "source": [
    "Hier schauen wir uns noch einmal an, wie viele Parameter unser Modell hat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-transcript",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-hampton",
   "metadata": {},
   "source": [
    "### Training des Modells\n",
    "\n",
    "Jetzt trainieren wir das Modell mit unseren Trainingsdaten.\n",
    "Jeden Durchlauf über die kompletten Trainingsdaten nennt man *Epoche*. \n",
    "\n",
    "Da wir alle Trainingsbilder auf einmal verwenden, lassen wir unser Modell weniger Epochen trainieren\n",
    "(`epochs = 20`). \n",
    "\n",
    "Am Ende kannst Du die *Lernkurve* des Modells sehen. **Wenn sie noch nach oben gehst, kannst Du das Modell weiter trainieren, indem Du die Zelle noch einmal aufrufst.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-discipline",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "epochs = 500\n",
    "\n",
    "with tqdm(range(epochs)) as iterator:\n",
    "\n",
    "    for epoch in iterator:\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            output = model(images)\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(output, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            prediction = torch.argmax(output, 1)\n",
    "            train_acc += (prediction == labels).sum().item()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        training_acc.append(train_acc/len(train_set))\n",
    "        training_loss.append(train_loss/len(train_set))\n",
    "\n",
    "        test_loss = 0\n",
    "        test_acc = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.cuda(), labels.cuda()\n",
    "                output = model(images)\n",
    "                loss = loss_fn(output, labels)\n",
    "                prediction = torch.argmax(output, 1)\n",
    "                test_acc += (prediction == labels).sum().item()\n",
    "                test_loss += loss.item()        \n",
    "            testing_acc.append(test_acc/len(test_set))\n",
    "            testing_loss.append(test_loss/len(test_set))\n",
    "\n",
    "        iterator.set_postfix_str(f\"train_acc: {train_acc/len(train_set):.2f} test_acc: {test_acc/len(test_set):.2f} train_loss: {train_loss/len(train_set):.2f} test_loss: {test_loss/len(test_set):.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "governmental-rainbow",
   "metadata": {},
   "source": [
    "Die folgenden beiden Zellen geben die Lernkurven aus und zeigen die *Genauigkeit* und den *Verlust* jeweils für die Trainings- und Testdaten an.\n",
    "\n",
    "**Was fällt Dir beim Vergleich der Kurven für Test- und Trainingsdaten auf?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(training_acc)), training_acc, label=\"train_acc\")\n",
    "plt.plot(range(len(testing_acc)), testing_acc, label=\"test_acc\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-observer",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(training_loss)), training_loss, label=\"train_loss\")\n",
    "plt.plot(range(len(testing_loss)), testing_loss, label=\"test_loss\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
